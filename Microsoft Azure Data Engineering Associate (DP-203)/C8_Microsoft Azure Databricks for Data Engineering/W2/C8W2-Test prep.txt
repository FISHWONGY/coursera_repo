Q.1 How do you list files in DBFS within a notebook?
>%fs ls /my-file-path

Q.2 How do you infer the data types and column names when you read a JSON file?
>spark.read.option("inferSchema", "true").json(jsonFile)

Q.3 Which of the following SparkSession functions returns a DataFrameReader
>read(..)

Q.4 When using a notebook and a spark session. We can read a CSV file. Which of the following can be used to view the first couple thousand characters of a file?
>%fs head /mnt/training/wikipedia/pageviews/pageviews_by_second.tsv

Q.5 You have created an Azure Databricks cluster, and you have access to a source file. fileName = "dbfs:/mnt/training/wikipedia/clickstream/2015_02_clickstream.tsv"
You need to determine the structure of the file. Which of the following commands will assist with determining what the column and data types are?
>.option("header", "false")

Q.6 In an Azure Databricks workspace you run the following command: %fs head /mnt/training/wikipedia/pageviews/pageviews_by_second.tsv
The partial output from this command is as follows:
"timestamp"   "site"   "requests"
"2015-03-16T00:09:55"   "mobile"   1595
"2015-03-16T00:10:39"   "mobile"   1544
"2015-03-16T00:19:39"   "desktop"   2460
"2015-03-16T00:38:11"   "desktop"   2237

Which of the following pieces of information can be inferred from the command and the output?
>The file has a header
>two columns are strings, and one column is a number

Q.7
In an Azure Databricks you wish to create a temporary view that will be accessible to multiple notebooks. Which of the following commands will provide this feature?
>createOrReplaceGlobalTempView(..)


Q.8
Which of the following is true in respect of Parquet Files?
>Open Source
>Efficient data compression
X designed for performance
X roww-oriented