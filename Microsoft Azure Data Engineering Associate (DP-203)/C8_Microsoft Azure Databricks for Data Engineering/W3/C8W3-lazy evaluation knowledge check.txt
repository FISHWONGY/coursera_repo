Q.1 Among the most powerful components of Spark are Spark SQL. At its core lies the Catalyst optimizer. When you execute code, Spark SQL uses Catalyst's general tree transformation framework in four phases.
>
1: analyzing a logical plan to resolve references
2. logical plan optimization
3: physical planning
4. code generation to compile parts of the query to Java bytecode

Q.2 Which of the following statements describes a wide transformation?
>A wide transformation requires sharing data across workers. It does so by shuffling data.

Q.3 Which of the following statements describes a narrow transformation?
> Can be applied per partition/worker with no need to share or shuffle data to other workers

Q.4 Which feature of Spark determines how your code is executed?
>Catalyst Optimiser

Q.5 Which feature of Spark of optimization is used in shuffling operations during wide transformations?
>Tungsten Record Format

Q.6 If you create a DataFrame that will read some data from Azure Blob Storage, and then you create another DataFrame by filtering the initial DataFrame. What feature of Spark causes these transformations to be analyzed?
>Lazy Execution

