Q.1 Stream processing is where you continuously incorporate new data into Data Lake storage and compute results. Which of the following are examples of Stream processing?
>IoT Device Data
>Game play events
>Bank Card Processing

Q.2
The following example creates a schema.
dataSchema = "Recorded_At timestamp, Device string, Index long, Model string, User string, _corrupt_record String, gt string, x double, y double, z double"
In SQL syntax this is referred to as which of the following?
>Data Definition Language (DDL)

Q.3
Which of the following syntax will allow you view the list of active streams in an Azure Databricks workspace?
>spark.streams.active

Q.4 What happens if the command option ("checkpointLocation", pointer-to-checkpoint directory) is not specified?
> When the streaming job stops, all state around the streaming job is lost, and upon restart, the job must start from scratch.

Q.5
Select the correct option to complete the statement below:
In Azure Databricks a schema is the definition of column names and data types. For file based streaming sources in Azure Databricks the schema is __________.
>User Defined

Q.6
In Spark Structured Streaming, what method should be used to read streaming data into a DataFrame?
>spark.readStream

Q.7
In Azure Databricks when creating a new user access token, the Lifetime setting of the access token can be manually set. What is the default Token Lifetime when creating a new token?
>90 Days

Q.8 What is the purpose of “Activities” in Azure Data Factory?
>To represent a processing step in a pipeline

Q.9
How can parameters be passed into an Azure Databricks notebook from Azure Data Factory?
>Use notebook widgets to define parameters that can be passed into the notebook